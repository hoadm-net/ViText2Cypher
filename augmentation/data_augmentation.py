#!/usr/bin/env python3
"""
Data Augmentation Pipeline for ViText2Cypher
Thá»±c hiá»‡n viá»‡c lÃ m giÃ u dá»¯ liá»‡u báº±ng cÃ¡ch dá»‹ch tá»± Ä‘á»™ng vá»›i few-shot learning
Sá»­ dá»¥ng KNN Ä‘á»ƒ tÃ¬m examplars tá»« báº£n dá»‹ch thá»§ cÃ´ng
"""

import json
import os
import random
import numpy as np
import argparse
from typing import List, Dict, Any
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
from tqdm import tqdm
import time

# Load environment variables
load_dotenv()

class DataAugmentationPipeline:
    def __init__(self, debug: bool = True):
        """Khá»Ÿi táº¡o pipeline vá»›i cÃ¡c cáº¥u hÃ¬nh tá»« .env"""
        self.debug = debug
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.embedding_model = os.getenv('EMBEDDING_MODEL', 'text-embedding-3-small')
        self.openai_model = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')
        self.max_tokens = int(os.getenv('OPENAI_MAX_TOKENS', '2000'))

        if self.debug:
            print(f"ğŸ”§ Config loaded:")
            print(f"   API Key: {'***' + self.openai_api_key[-10:] if self.openai_api_key else 'NOT FOUND'}")
            print(f"   Model: {self.openai_model}")
            print(f"   Embedding Model: {self.embedding_model}")

        # Khá»Ÿi táº¡o OpenAI embeddings
        try:
            self.embeddings = OpenAIEmbeddings(
                openai_api_key=self.openai_api_key,
                model=self.embedding_model
            )
            if self.debug:
                print("âœ“ OpenAI Embeddings initialized")
        except Exception as e:
            print(f"âœ— Error initializing embeddings: {e}")
            raise

        # Khá»Ÿi táº¡o OpenAI client
        self.client = OpenAI(api_key=self.openai_api_key)

        # Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c load
        self.manual_translation_data = []
        self.train_data = []
        self.manual_embeddings = []

        # Load template tá»« file
        self.translation_template = self._load_template()

    def _load_template(self) -> PromptTemplate:
        """Load template tá»« file"""
        template_file = '../templates/few_shot_translation.txt'
        try:
            with open(template_file, 'r', encoding='utf-8') as f:
                template_content = f.read()

            if self.debug:
                print(f"âœ“ Template loaded from {template_file}")

            return PromptTemplate(
                input_variables=["schema", "examples", "question"],
                template=template_content
            )
        except Exception as e:
            print(f"âœ— Error loading template: {e}")
            print(f"Creating default template...")
            # Fallback template
            default_template = """Báº¡n lÃ  chuyÃªn gia dá»‹ch thuáº­t chuyÃªn dá»‹ch cÃ¢u há»i tá»« tiáº¿ng Anh sang tiáº¿ng Viá»‡t.

Schema: {schema}

Examples: {examples}

Question: {question}

Vietnamese:"""
            return PromptTemplate(
                input_variables=["schema", "examples", "question"],
                template=default_template
            )

    def load_manual_translation(self, file_path: str = '../data/manual_translation.json'):
        """Load manual translation data - sá»­ dá»¥ng cache náº¿u cÃ³"""
        try:
            # Kiá»ƒm tra xem cÃ³ file cache vá»›i embeddings khÃ´ng
            cache_file = file_path.replace('.json', '_with_embeddings.json')
            
            if os.path.exists(cache_file):
                if self.debug:
                    print(f"ğŸ”„ Loading from cache: {cache_file}")
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.manual_translation_data = json.load(f)
                
                # Load embeddings tá»« cache
                self.manual_embeddings = [item['embedding_question'] for item in self.manual_translation_data]
                if self.debug:
                    print(f"âœ“ Loaded {len(self.manual_translation_data)} samples with embeddings from cache")
                return True
            
            # Náº¿u khÃ´ng cÃ³ cache, load file gá»‘c
            with open(file_path, 'r', encoding='utf-8') as f:
                self.manual_translation_data = json.load(f)

            # Kiá»ƒm tra embeddings trong file gá»‘c
            has_embeddings = any('embedding_question' in item for item in self.manual_translation_data)
            if has_embeddings:
                if self.debug:
                    print(f"âœ“ ÄÃ£ load {len(self.manual_translation_data)} máº«u tá»« {file_path}")
                # Load embeddings
                self.manual_embeddings = [item['embedding_question'] for item in self.manual_translation_data]
                return True
            else:
                if self.debug:
                    print(f"âš ï¸ File khÃ´ng cÃ³ embeddings - cáº§n táº¡o cache embeddings...")
                    print(f"ğŸ’¡ Äá»ƒ tiáº¿t kiá»‡m cost, hÃ£y táº¡o cache trÆ°á»›c:")
                    print(f"   python create_embeddings_cache.py")
                return False

        except Exception as e:
            print(f"âœ— Lá»—i khi load {file_path}: {e}")
            return False

    def _create_embeddings_for_manual_data(self) -> bool:
        """Tá»± táº¡o embeddings cho manual translation data"""
        try:
            if self.debug:
                print("ğŸ”„ Äang táº¡o embeddings cho manual translation data...")
            
            self.manual_embeddings = []
            for i, item in enumerate(self.manual_translation_data):
                if self.debug and i % 100 == 0:
                    print(f"   Äang xá»­ lÃ½ {i}/{len(self.manual_translation_data)}...")
                
                embedding = self.embeddings.embed_query(item['question'])
                self.manual_embeddings.append(embedding)
                item['embedding_question'] = embedding
                
                # Delay nhá» Ä‘á»ƒ trÃ¡nh rate limit
                time.sleep(0.1)
            
            if self.debug:
                print(f"âœ“ ÄÃ£ táº¡o {len(self.manual_embeddings)} embeddings")
            return True
            
        except Exception as e:
            print(f"âœ— Lá»—i táº¡o embeddings: {e}")
            return False

    def load_data(self):
        """Load dá»¯ liá»‡u tá»« cÃ¡c file JSON"""
        if self.debug:
            print("ğŸ”„ Äang load dá»¯ liá»‡u...")

        # Load manual translation vá»›i embeddings
        if not self.load_manual_translation():
            print("âŒ KhÃ´ng thá»ƒ load manual translation data")
            return False

        # Hiá»ƒn thá»‹ cáº¥u trÃºc
        if self.debug and self.manual_translation_data:
            sample = self.manual_translation_data[0]
            print(f"   Cáº¥u trÃºc máº«u: {list(sample.keys())}")

            # Kiá»ƒm tra trÆ°á»ng translation
            translation_field = None
            if 'translation' in sample:
                translation_field = 'translation'
            elif 'question_vi' in sample:
                translation_field = 'question_vi'

            if translation_field:
                print(f"   TrÆ°á»ng dá»‹ch: '{translation_field}'")
            else:
                print("   âš ï¸ KhÃ´ng tÃ¬m tháº¥y trÆ°á»ng dá»‹ch")

        # Load train data
        try:
            with open('../data/train.json', 'r', encoding='utf-8') as f:
                self.train_data = json.load(f)
            if self.debug:
                print(f"âœ“ ÄÃ£ load {len(self.train_data)} máº«u tá»« train.json")
        except Exception as e:
            print(f"âœ— Lá»—i load train.json: {e}")
            return False

        return True

    def find_similar_examples(self, target_question: str, k: int = 2) -> List[Dict[str, Any]]:
        """TÃ¬m k máº«u tÆ°Æ¡ng tá»± nháº¥t báº±ng KNN vá»›i cosine similarity"""
        try:
            # Táº¡o embedding cho cÃ¢u há»i target
            target_embedding = self.embeddings.embed_query(target_question)

            # TÃ­nh similarity vá»›i táº¥t cáº£ embeddings
            similarities = []
            for i, manual_embedding in enumerate(self.manual_embeddings):
                similarity = cosine_similarity(
                    [target_embedding],
                    [manual_embedding]
                )[0][0]
                similarities.append((i, similarity))

            # Sáº¯p xáº¿p theo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giáº£m dáº§n
            similarities.sort(key=lambda x: x[1], reverse=True)

            # Láº¥y k máº«u tÆ°Æ¡ng tá»± nháº¥t
            top_k_indices = [idx for idx, _ in similarities[:k]]
            examples = [self.manual_translation_data[i] for i in top_k_indices]

            if self.debug:
                similarities_scores = [sim for _, sim in similarities[:k]]
                print(f"   ğŸ“Š Top {k} similarity scores: {similarities_scores}")

            return examples

        except Exception as e:
            if self.debug:
                print(f"âœ— Lá»—i tÃ¬m examples: {e}")
            # Fallback: random examples
            return random.sample(self.manual_translation_data, min(k, len(self.manual_translation_data)))

    def format_examples(self, examples: List[Dict[str, Any]]) -> str:
        """Format examples thÃ nh string cho few-shot prompt"""
        example_strings = []

        for i, example in enumerate(examples, 1):
            # Láº¥y translation tá»« trÆ°á»ng cÃ³ sáºµn
            translation = example.get('translation') or example.get('question_vi', '[Cáº§n dá»‹ch]')

            example_str = f"""
Example {i}:
English: {example['question']}
Vietnamese: {translation}
Schema: {example['schema'][:200]}...
Cypher: {example['cypher']}
"""
            example_strings.append(example_str)

        return "\n".join(example_strings)

    def translate_question(self, question: str, schema: str, examples: List[Dict[str, Any]]) -> str:
        """Dá»‹ch cÃ¢u há»i sá»­ dá»¥ng few-shot learning"""
        try:
            # Format examples
            examples_text = self.format_examples(examples)

            # Táº¡o prompt tá»« template
            prompt = self.translation_template.format(
                schema=schema[:500] + "..." if len(schema) > 500 else schema,  # RÃºt gá»n schema
                examples=examples_text,
                question=question
            )

            # Gá»i OpenAI API
            response = self.client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {"role": "system", "content": "Báº¡n lÃ  má»™t chuyÃªn gia dá»‹ch thuáº­t chuyÃªn nghiá»‡p."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=0.3
            )

            translation = response.choices[0].message.content.strip()

            # LÃ m sáº¡ch káº¿t quáº£
            if translation.startswith("Vietnamese:"):
                translation = translation.replace("Vietnamese:", "").strip()

            return translation

        except Exception as e:
            if self.debug:
                print(f"âœ— Lá»—i dá»‹ch cÃ¢u há»i: {e}")
            return f"[Lá»—i dá»‹ch] {question}"

    def augment_data(self, start_idx: int = 0, end_idx: int = None) -> List[Dict[str, Any]]:
        """Táº¡o dá»¯ liá»‡u tÄƒng cÆ°á»ng báº±ng few-shot translation"""
        # TÃ­nh sá»‘ máº«u tá»« start vÃ  end
        if end_idx is None:
            actual_samples = 4000
            print(f"\nğŸ”„ Äang táº¡o {actual_samples} máº«u dá»¯ liá»‡u tÄƒng cÆ°á»ng...")
            print(f"   ğŸ“ Báº¯t Ä‘áº§u tá»«: {start_idx}")
        else:
            actual_samples = end_idx - start_idx
            print(f"\nğŸ”„ Äang táº¡o {actual_samples} máº«u dá»¯ liá»‡u tÄƒng cÆ°á»ng...")
            print(f"   ğŸ“ Pháº¡m vi: tá»« {start_idx} Ä‘áº¿n {end_idx - 1}")

        # BÆ¯á»šC 1: Load táº¥t cáº£ cÃ¢u há»i Ä‘Ã£ tá»“n táº¡i (manual + logs.txt)
        existing_questions = self.load_existing_questions()

        augmented_data = []
        used_train_indices = set()
        attempts = 0
        max_attempts = actual_samples * 10  # TrÃ¡nh vÃ²ng láº·p vÃ´ táº­n

        # Progress bar vá»›i tqdm
        with tqdm(total=actual_samples, desc="Translating questions", unit="samples") as pbar:
            while len(augmented_data) < actual_samples and attempts < max_attempts:
                attempts += 1

                # BÆ¯á»šC 2: Random chá»n 1 máº«u tá»« train.json
                train_idx = random.randint(0, len(self.train_data) - 1)

                # Skip náº¿u index Ä‘Ã£ dÃ¹ng rá»“i
                if train_idx in used_train_indices:
                    continue

                train_sample = self.train_data[train_idx]
                train_question = train_sample['question']

                # BÆ¯á»šC 3: Kiá»ƒm tra cÃ¢u há»i Ä‘Ã£ tá»“n táº¡i chÆ°a?
                if train_question in existing_questions:
                    used_train_indices.add(train_idx)
                    continue  # Random láº¡i

                try:
                    # BÆ¯á»šC 4: TÃ¬m similar examples báº±ng KNN vÃ  dá»‹ch
                    similar_examples = self.find_similar_examples(train_question, k=2)

                    # Dá»‹ch cÃ¢u há»i vá»›i few-shot
                    translation = self.translate_question(
                        question=train_question,
                        schema=train_sample['schema'],
                        examples=similar_examples
                    )

                    # Táº¡o máº«u dá»¯ liá»‡u má»›i
                    augmented_sample = {
                        'question': train_question,
                        'schema': train_sample['schema'],
                        'cypher': train_sample['cypher'],
                        'translation': translation
                    }

                    augmented_data.append(augmented_sample)
                    used_train_indices.add(train_idx)

                    # ThÃªm cÃ¢u há»i má»›i vÃ o existing_questions Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
                    existing_questions.add(train_question)

                    pbar.update(1)

                    # Delay ngáº¯n Ä‘á»ƒ trÃ¡nh rate limit
                    time.sleep(0.2)

                except Exception as e:
                    if self.debug:
                        tqdm.write(f"âœ— Lá»—i máº«u {train_idx}: {str(e)[:50]}...")
                    used_train_indices.add(train_idx)
                    continue

        if attempts >= max_attempts:
            print(f"âš ï¸ Äáº¡t giá»›i háº¡n {max_attempts} láº§n thá»­, táº¡o Ä‘Æ°á»£c {len(augmented_data)}/{actual_samples} máº«u")

        print(f"âœ… HoÃ n thÃ nh: {len(augmented_data)} máº«u dá»¯ liá»‡u tÄƒng cÆ°á»ng")
        return augmented_data

    def save_checkpoint(self, data: List[Dict[str, Any]], checkpoint_file: str):
        """LÆ°u checkpoint"""
        try:
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            if self.debug:
                print(f"âœ— Lá»—i lÆ°u checkpoint: {e}")

    def load_checkpoint(self, checkpoint_file: str) -> List[Dict[str, Any]]:
        """Load checkpoint"""
        try:
            with open(checkpoint_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ“ Load checkpoint: {len(data)} máº«u tá»« {checkpoint_file}")
            return data
        except Exception as e:
            if self.debug:
                print(f"âš ï¸ KhÃ´ng load Ä‘Æ°á»£c checkpoint {checkpoint_file}: {e}")
            return []

    def save_final_data(self, augmented_data: List[Dict[str, Any]], output_file: str = '../data/augmented_data.json'):
        """LÆ°u CHá»ˆ dá»¯ liá»‡u má»›i Ä‘Æ°á»£c dá»‹ch - KHÃ”NG bao gá»“m dá»¯ liá»‡u manual cÅ©"""
        print(f"\nğŸ’¾ Äang lÆ°u dá»¯ liá»‡u má»›i vÃ o {output_file}...")

        # CHá»ˆ lÆ°u dá»¯ liá»‡u augmented_data (dá»¯ liá»‡u má»›i Ä‘Æ°á»£c dá»‹ch)
        # KHÃ”NG gá»™p vá»›i manual_data_clean nhÆ° trÆ°á»›c
        final_data = augmented_data

        # LÆ°u file
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… ÄÃ£ lÆ°u {len(final_data)} máº«u dá»¯ liá»‡u Má»šI:")
        print(f"   ğŸ“Š Dá»¯ liá»‡u tÄƒng cÆ°á»ng (má»›i dá»‹ch): {len(augmented_data)} máº«u")
        print(f"   ğŸ“ File: {output_file}")
        print(f"   âš ï¸ LÆ°u Ã½: File chá»‰ chá»©a dá»¯ liá»‡u Má»šI, khÃ´ng bao gá»“m manual_translation.json")

        return output_file

    def run_pipeline(self, start_idx: int = 0, end_idx: int = None, output_file: str = None):
        """Cháº¡y pipeline Ä‘Æ¡n giáº£n - khÃ´ng cÃ³ checkpoint/resume"""
        print("ğŸš€ Data Augmentation Pipeline - Few-Shot Translation")
        print("="*60)

        try:
            # Load dá»¯ liá»‡u
            if not self.load_data():
                return None

            # Táº¡o dá»¯ liá»‡u tÄƒng cÆ°á»ng
            augmented_data = self.augment_data(start_idx, end_idx)

            if not augmented_data:
                print("âŒ KhÃ´ng táº¡o Ä‘Æ°á»£c dá»¯ liá»‡u tÄƒng cÆ°á»ng")
                return None

            # Táº¡o tÃªn file output máº·c Ä‘á»‹nh
            if output_file is None:
                if end_idx is None:
                    output_file = f'../data/augmented_data_{start_idx}_{start_idx + 4000}.json'
                else:
                    output_file = f'../data/augmented_data_{start_idx}_{end_idx}.json'

            # LÆ°u káº¿t quáº£ cuá»‘i
            result_file = self.save_final_data(augmented_data, output_file)

            print(f"\nğŸ‰ HoÃ n thÃ nh pipeline!")
            print(f"ğŸ“ Káº¿t quáº£: {result_file}")

            return result_file

        except Exception as e:
            print(f"\nğŸ’¥ Lá»—i pipeline: {e}")
            if self.debug:
                import traceback
                traceback.print_exc()
            return None

    def load_existing_questions(self):
        """Load táº¥t cáº£ cÃ¢u há»i Ä‘Ã£ tá»“n táº¡i tá»« manual_translation vÃ  logs.txt"""
        existing_questions = set()

        # Load tá»« manual_translation_with_embeddings.json
        for item in self.manual_translation_data:
            existing_questions.add(item['question'])

        # Load tá»« logs.txt náº¿u tá»“n táº¡i
        logs_file = '../data/logs.txt'
        if os.path.exists(logs_file):
            try:
                with open(logs_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        question = line.strip()
                        if question:
                            existing_questions.add(question)
                if self.debug:
                    print(f"âœ“ Load thÃªm cÃ¢u há»i tá»« {logs_file}")
            except Exception as e:
                if self.debug:
                    print(f"âš ï¸ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c {logs_file}: {e}")

        if self.debug:
            print(f"ğŸ” Tá»•ng {len(existing_questions)} cÃ¢u há»i Ä‘Ã£ tá»“n táº¡i (cáº§n trÃ¡nh)")

        return existing_questions

def main():
    parser = argparse.ArgumentParser(description='Data Augmentation Pipeline - Few-Shot Translation')
    parser.add_argument('--start', '-s',
                       type=int, default=0,
                       help='Vá»‹ trÃ­ báº¯t Ä‘áº§u (default: 0)')
    parser.add_argument('--end', '-e',
                       type=int, default=None,
                       help='Vá»‹ trÃ­ káº¿t thÃºc (default: None, sáº½ táº¡o 4000 máº«u)')
    parser.add_argument('--output', '-o',
                       type=str, default=None,
                       help='File output (default: ../data/augmented_data_{start}_{end}.json)')
    parser.add_argument('--debug',
                       action='store_true',
                       help='Báº­t cháº¿ Ä‘á»™ debug')

    args = parser.parse_args()

    # TÃ­nh sá»‘ máº«u tá»« start vÃ  end
    if args.end is None:
        num_samples = 4000
        end_display = f"{args.start + 4000}"
    else:
        num_samples = args.end - args.start
        end_display = str(args.end)

    print("ğŸ¤– Data Augmentation Pipeline")
    print("=" * 40)
    print(f"ğŸ¯ Samples: {num_samples}")
    print(f"ğŸ“ Range: {args.start} -> {end_display}")
    if args.output:
        print(f"ğŸ“ Output: {args.output}")
    else:
        output_name = f"../data/augmented_data_{args.start}_{end_display}.json"
        print(f"ğŸ“ Output: {output_name}")
    print("=" * 40)

    # Khá»Ÿi táº¡o vÃ  cháº¡y pipeline
    pipeline = DataAugmentationPipeline(debug=args.debug)
    result = pipeline.run_pipeline(
        start_idx=args.start,
        end_idx=args.end,
        output_file=args.output
    )

    if result:
        print(f"\nâœ… Success! Result: {result}")
    else:
        print("\nâŒ Pipeline failed!")
        exit(1)

if __name__ == "__main__":
    main()
